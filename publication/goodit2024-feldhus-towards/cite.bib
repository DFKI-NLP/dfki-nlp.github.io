@inproceedings{10.1145/3677525.3678665,
author = {Feldhus, Nils and Anagnostopoulou, Aliki and Wang, Qianli and Alshomary, Milad and Wachsmuth, Henning and Sonntag, Daniel and M\"{o}ller, Sebastian},
title = {Towards Modeling and Evaluating Instructional Explanations in Teacher-Student Dialogues},
year = {2024},
isbn = {9798400710940},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677525.3678665},
doi = {10.1145/3677525.3678665},
abstract = {For dialogues in which teachers explain difficult concepts to students, didactics research often debates which teaching strategies lead to the best learning outcome. In this paper, we test if LLMs can reliably annotate such explanation dialogues, s.t. they could assist in lesson planning and tutoring systems. We first create a new annotation scheme of teaching acts aligned with contemporary teaching models and re-annotate a dataset of conversational explanations about communicating scientific understanding in teacher-student settings on five levels of the explainee’s expertise: ReWIRED contains three layers of acts (Teaching, Explanation, Dialogue) with increased granularity (span-level). We then evaluate language models on the labeling of such acts and find that the broad range and structure of the proposed labels is hard to model for LLMs such as GPT-3.5/-4 via prompting, but a fine-tuned BERT can perform both act classification and span labeling well. Finally, we operationalize a series of quality metrics for instructional explanations in the form of a test suite, finding that they match the five expertise levels well.1},
booktitle = {Proceedings of the 2024 International Conference on Information Technology for Social Good},
pages = {225–230},
numpages = {6},
keywords = {Dialogue, Discourse Analysis, Evaluation, Explanations},
location = {Bremen, Germany},
series = {GoodIT '24}
}
