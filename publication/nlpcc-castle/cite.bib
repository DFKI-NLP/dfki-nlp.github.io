@InProceedings{10.1007/978-3-030-88483-3_24,
author="Castle, Steffen
and Schwarzenberg, Robert
and Pourvali, Mohsen",
editor="Wang, Lu
and Feng, Yansong
and Hong, Yu
and He, Ruifang",
title="Detecting Covariate Drift with Explanations",
booktitle="Natural Language Processing and Chinese Computing",
year="2021",
publisher="Springer International Publishing",
address="Cham",
pages="317--322",
abstract="Detecting when there is a domain drift between training and inference data is important for any model evaluated on data collected in real time. Many current data drift detection methods only utilize input features to detect domain drift. While effective, these methods disregard the model's evaluation of the data, which may be a significant source of information about the data domain. We propose to use information from the model in the form of explanations, specifically gradient times input, in order to utilize this information. Following the framework of Rabanser et al. [11], we combine these explanations with two-sample tests in order to detect a shift in distribution between training and evaluation data. Promising initial experiments show that explanations provide useful information for detecting shift, which potentially improves upon the current state-of-the-art.",
isbn="978-3-030-88483-3"
}

