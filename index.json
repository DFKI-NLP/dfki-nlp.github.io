[{"authors":["admin"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://dfki-nlp.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"","tags":null,"title":"German Research Center for Artificial Intelligence - Speech \u0026 Language Understanding","type":"authors"},{"authors":null,"categories":null,"content":"","date":1576508108,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576508108,"objectID":"9dc907091b510ea2f58fa3e883433bfb","permalink":"https://dfki-nlp.github.io/project/daystream/","publishdate":"2019-12-16T15:55:08+01:00","relpermalink":"/project/daystream/","section":"project","summary":"","tags":["Language Understanding","Information Extraction","Mobility"],"title":"Daystream","type":"project"},{"authors":null,"categories":null,"content":"","date":1576508108,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576508108,"objectID":"2fd1a9eee61a268e57a10ee4b5e09ea7","permalink":"https://dfki-nlp.github.io/dataset/dfki-product-corpus/","publishdate":"2019-12-16T15:55:08+01:00","relpermalink":"/dataset/dfki-product-corpus/","section":"dataset","summary":"The dataset consists of 174 English web pages and social media posts annotated for product and company named entities, and the relation CompanyProvidesProduct.","tags":["Language Understanding","Information Extraction","Mobility"],"title":"DFKI Product Corpus","type":"dataset"},{"authors":["Robert Schwarzenberg","Marc Hübner","David Harbecke","Christoph Alt","Leonhard Hennig"],"categories":[],"content":"","date":1569476323,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569476323,"objectID":"a473d0f5238b0e0755c80265a795c54a","permalink":"https://dfki-nlp.github.io/publication/layerwise-relevance-visualization-in-convolutional-text-graph-classifiers/","publishdate":"2019-09-26T07:38:43+02:00","relpermalink":"/publication/layerwise-relevance-visualization-in-convolutional-text-graph-classifiers/","section":"publication","summary":"Representations in the hidden layers of Deep Neural Networks (DNN) are often hard to interpret since it is difficult to project them into an interpretable domain. Graph Convolutional Networks (GCN) allow this projection, but existing explainability methods do not exploit this fact, i.e. do not focus their explanations on intermediate states. In this work, we present a novel method that traces and visualizes features that contribute to a classification decision in the visible and hidden layers of a GCN. Our method exposes hidden cross-layer dynamics in the input graph structure. We experimentally demonstrate that it yields meaningful layerwise explanations for a GCN sentence classifier.","tags":[],"title":"Layerwise Relevance Visualization in Convolutional Text Graph Classifiers","type":"publication"},{"authors":["Christoph Alt","Marc Hübner","Leonhard Hennig"],"categories":[],"content":"","date":1564358400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1564358400,"objectID":"f4eb940c053dcbb0e51e8bc6f3c1280c","permalink":"https://dfki-nlp.github.io/publication/fine-tuning-pre-trained-transformer-language-models-to-distantly-supervised-relation-extraction/","publishdate":"2019-08-26T14:09:16+02:00","relpermalink":"/publication/fine-tuning-pre-trained-transformer-language-models-to-distantly-supervised-relation-extraction/","section":"publication","summary":"We show that generative language model pre-training combined with selective attention improves recall for long-tail relations in distantly supervised neural relation extraction.","tags":[],"title":"Fine-Tuning Pre-Trained Transformer Language Models to Distantly Supervised Relation Extraction","type":"publication"},{"authors":["Christoph Alt","Marc Hübner","Leonhard Hennig"],"categories":[],"content":"","date":1558310400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558310400,"objectID":"ba406529ce40592af9b0e1d9b0ba770f","permalink":"https://dfki-nlp.github.io/publication/improving-relation-extraction-by-pre-trained-language-representations/","publishdate":"2019-08-26T14:36:10+02:00","relpermalink":"/publication/improving-relation-extraction-by-pre-trained-language-representations/","section":"publication","summary":"We show that transfer learning through generative language model pre-training improves supervised neural relation extraction, achieving new state-of-the-art performance on TACRED and SemEval 2010 Task 8.","tags":[],"title":"Improving Relation Extraction by Pre-Trained Language Representations","type":"publication"},{"authors":["Roland Roller","Christoph Alt","Laura Seiffe","He Wang"],"categories":[],"content":"","date":1543622400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1543622400,"objectID":"433a17498e14b803ea57862a8b6aadd1","permalink":"https://dfki-nlp.github.io/publication/mex-an-information-extraction-platform-for-german-medical-text/","publishdate":"2019-08-26T14:36:19+02:00","relpermalink":"/publication/mex-an-information-extraction-platform-for-german-medical-text/","section":"publication","summary":"","tags":[],"title":"mEx - an Information Extraction Platform for German Medical Text","type":"publication"},{"authors":["David Harbecke","Robert Schwarzenberg","Christoph Alt"],"categories":[],"content":"","date":1541116800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1541116800,"objectID":"68f68d704af9c42e6dc03edd211ae360","permalink":"https://dfki-nlp.github.io/publication/learning-explanations-from-language-data/","publishdate":"2019-08-26T14:36:16+02:00","relpermalink":"/publication/learning-explanations-from-language-data/","section":"publication","summary":"PatternAttribution is a recent method, introduced in the vision domain, that explains classifications of deep neural networks. We demonstrate that it also generates meaningful interpretations in the language domain.","tags":[],"title":"Learning Explanations From Language Data","type":"publication"}]