---
# Documentation: https://wowchemy.com/docs/managing-content/

title: "One paper by DFKI-NLP authors accepted to RepL4NLP 2025 (at NAACL 2025)"
subtitle: ""
summary: ""
authors: []
tags: []
categories: []
date: 2025-05-04T09:24:01+02:00
lastmod: 2025-05-04T09:24:01+02:00
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ""
  focal_point: ""
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
---

One paper originating from research in the TRAILS project has been accepted to the [10th Workshop on Representation Learning for NLP (RepL4NLP 2025)](https://sites.google.com/view/repl4nlp2025), co-located with [NAACL 2025](https://2025.naacl.org/). In the paper, we reimagine classical probing to evaluate knowledge transfer from simple source to more complex target tasks. Instead of probing frozen representations from a complex source task on diverse simple target probing tasks (as usually done in probing), we explore the effectiveness of embeddings from multiple simple source tasks on a single target task. Our findings reveal that task embeddings vary significantly in utility for coreference resolution, with semantic similarity tasks (e.g., paraphrase detection) proving most beneficial. Additionally, representations from intermediate layers of fine-tuned models often outperform those from final layers.

{{< cite page="/publication/anikina-etal-2025-reverse" view="4" >}}








